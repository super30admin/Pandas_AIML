{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pandas Lab — FAANG-Level Hands-On\n",
        "\n",
        "**Goal:** Build strong intuition for Pandas transformations used in ML pipelines (joins, groupby, leakage-safe features).\n",
        "\n",
        "**Outcome:** You can write correct, scalable Pandas code and explain common gotchas (join explosion, leakage, apply misuse).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def check(name: str, cond: bool):\n",
        "    if not cond:\n",
        "        raise AssertionError(f'Failed: {name}')\n",
        "    print(f'OK: {name}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 0 — Synthetic Dataset (Interview-Friendly)\n",
        "We’ll use synthetic tables to mirror typical ML feature engineering tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(   user_id country  signup_ts\n",
              " 0      101      IN 2025-01-01\n",
              " 1      102      US 2025-01-03\n",
              " 2      103      IN 2025-01-04\n",
              " 3      104      CA 2025-01-10,\n",
              "    user_id   event_ts        event  amount\n",
              " 0      104 2025-01-17         view     0.0\n",
              " 1      103 2025-01-04         view     0.0\n",
              " 2      103 2025-01-02         view     0.0\n",
              " 3      102 2025-01-18  add_to_cart     0.0\n",
              " 4      102 2025-01-01         view     0.0)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rng = np.random.default_rng(0)\n",
        "\n",
        "users = pd.DataFrame({ # converted dict to DataFrame for better handling\n",
        "    'user_id': [101, 102, 103, 104],\n",
        "    'country': ['IN', 'US', 'IN', 'CA'],\n",
        "    'signup_ts': pd.to_datetime(['2025-01-01', '2025-01-03', '2025-01-04', '2025-01-10'])\n",
        "})\n",
        "\n",
        "events = pd.DataFrame({\n",
        "    'user_id': rng.choice(users['user_id'], size=30, replace=True),\n",
        "    'event_ts': pd.to_datetime('2025-01-01') + pd.to_timedelta(rng.integers(0, 20, size=30), unit='D'),\n",
        "    'event': rng.choice(['view', 'add_to_cart', 'purchase'], size=30, replace=True, p=[0.7, 0.2, 0.1]),\n",
        "    'amount': rng.choice([0, 0, 0, 19.99, 49.99, 99.99], size=30, replace=True),\n",
        "})\n",
        "\n",
        "# Ensure amount > 0 only for purchases (simple realism)\n",
        "events.loc[events['event'] != 'purchase', 'amount'] = 0\n",
        "\n",
        "users, events.head() # return first 5 rows of dataframe\n",
        "\n",
        "# events\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1 — DataFrame Fundamentals\n",
        "\n",
        "### Task 1.1: Basic filtering + new columns\n",
        "\n",
        "Create:\n",
        "- `purchases`: rows where `event == 'purchase'`\n",
        "- add column `event_day` = date (no time)\n",
        "\n",
        "# HINT:\n",
        "- Use boolean indexing\n",
        "- Use `.dt.floor('D')` or `.dt.date` (but prefer datetime64)\n",
        "\n",
        "**Explain:** Why does vectorized `.dt` beat per-row parsing?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_id              int64\n",
            "event_ts    datetime64[ns]\n",
            "event               object\n",
            "amount             float64\n",
            "dtype: object\n",
            "OK: purchases_only\n",
            "OK: event_day_dtype\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "purchases = events[events['event'] == 'purchase'] # Every row that matches this criteria returns True and gets displayed\n",
        "purchases = purchases.copy() # created a copy so that i don't mess with original dataframe\n",
        "print(purchases.dtypes)\n",
        "purchases['event_day'] = purchases['event_ts'].dt.floor('D')\n",
        "\n",
        "purchases\n",
        "\n",
        "check('purchases_only', set(purchases['event'].unique()) <= {'purchase'})\n",
        "check('event_day_dtype', str(purchases['event_day'].dtype).startswith('datetime'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2 — GroupBy (Core for Features)\n",
        "\n",
        "### Task 2.1: Per-user aggregates\n",
        "Compute per-user features:\n",
        "- `n_events`\n",
        "- `n_purchases`\n",
        "- `total_revenue` (sum of amount)\n",
        "\n",
        "# HINT:\n",
        "- Use `groupby('user_id').agg(...)`\n",
        "- For `n_purchases`, use conditional aggregation\n",
        "\n",
        "**FAANG gotcha:** Counting purchases using `amount>0` vs `event=='purchase'` can diverge if data is messy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   user_id  n_events  n_purchases  total_revenue\n",
            "0      101         6            1          99.99\n",
            "1      102         4            0           0.00\n",
            "2      103        12            0           0.00\n",
            "3      104         8            0           0.00\n",
            "OK: has_user_id\n",
            "OK: has_total_revenue\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "# agg returns 1 row per group, for all the users which are repeating i got 1 response\n",
        "# agg is used as a group level funtion\n",
        "# if i have 4 unique user_id i will get 4 rows in output\n",
        "# events.assign = create a new dataframe and by using aggregate we are able to create 1 row per user_id\n",
        "user_features = (\n",
        "    events.assign(is_purchase=(events['event'] == 'purchase')).groupby('user_id', as_index=True).agg(\n",
        "        n_events=('event', 'size'),\n",
        "        n_purchases=('is_purchase', 'sum'),\n",
        "        total_revenue=('amount', 'sum'),\n",
        "    )\n",
        ")\n",
        "\n",
        "user_features = user_features.reset_index()\n",
        "print(user_features)\n",
        "check('has_user_id', 'user_id' in user_features.columns)\n",
        "check('has_total_revenue', 'total_revenue' in user_features.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2.2: GroupBy transform (row-level feature)\n",
        "\n",
        "Add a column to `events` called `user_event_count` = number of events for that user.\n",
        "\n",
        "# HINT:\n",
        "- Use `groupby(...).transform('count')`\n",
        "\n",
        "**Explain:** Why is `transform` different from `agg`?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: user_event_count_nonnull\n",
            "OK: counts_positive\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "# transform = row level feature\n",
        "# if i have 30 rows in events dataframe after transform i will still have 30 rows\n",
        "events2 = events.copy()\n",
        "events2['user_event_count'] = events2.groupby('user_id')['event'].transform('size') # groupby('user_id') = Groups various users based on user_id and counts number of events per user\n",
        "# After i have grouped them i am looking at event column and using transform size which compute number of rows per user \n",
        "# print(events2)\n",
        "\n",
        "check('user_event_count_nonnull', events2['user_event_count'].notna().all())\n",
        "check('counts_positive', (events2['user_event_count'] > 0).all())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3 — Joins & Merge (Feature Table Building)\n",
        "\n",
        "### Task 3.1: Join user features back to users\n",
        "\n",
        "Create `user_table` by joining `users` with `user_features` on `user_id`.\n",
        "\n",
        "# HINT:\n",
        "- Use `merge(..., how='left')`\n",
        "- Fill missing aggregates with 0\n",
        "\n",
        "**FAANG gotcha:** If you accidentally do a many-to-many join, row count explodes. Always validate row counts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: rowcount_preserved\n",
            "   user_id country  signup_ts  n_events  n_purchases  total_revenue\n",
            "0      101      IN 2025-01-01         6            1          99.99\n",
            "1      102      US 2025-01-03         4            0           0.00\n",
            "2      103      IN 2025-01-04        12            0           0.00\n",
            "3      104      CA 2025-01-10         8            0           0.00\n"
          ]
        }
      ],
      "source": [
        "# Joins is operation that combines 2 dataframes(table) based on common column\n",
        "# inner join = only keep rows that have matching keys in both left and right tables \n",
        "# left join = keep all rows from left table even if there is no match in right table\n",
        "# right join = keep all rows from right table even if there is no match in left table \n",
        "# outer join = keep all rows from both tables, fill with NaN where there is no match/ Union of left and right join\n",
        "# TODO\n",
        "\n",
        "user_table = users.merge(\n",
        "    user_features,\n",
        "    on='user_id',\n",
        "    how='left',  # Keep all users, even those with no events\n",
        ")\n",
        "\n",
        "# Fill NaNs for users with no events\n",
        "for col in ['n_events', 'n_purchases', 'total_revenue']:\n",
        "    if col in user_table.columns:\n",
        "        user_table[col] = user_table[col].fillna(0)\n",
        "\n",
        "check('rowcount_preserved', len(user_table) == len(users))\n",
        "print(user_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 3.2: Join explosion debugging (mini)\n",
        "\n",
        "Construct a tiny example where a join becomes many-to-many and explodes rows. Then fix it.\n",
        "\n",
        "# HINT:\n",
        "- Create `left` with duplicate keys\n",
        "- Create `right` with duplicate keys\n",
        "- Merge and observe rowcount\n",
        "\n",
        "**Explain:** What join cardinality do you expect (1:1, 1:n, n:1, n:n)?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "left rows 3 right rows 3 merged rows 5\n",
            "fixed rows 3\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "\n",
        "left = pd.DataFrame({'k': [1, 1, 2], 'l': ['a', 'b', 'c']})\n",
        "right = pd.DataFrame({'k': [1, 1, 2], 'r': ['x', 'y', 'z']})\n",
        "exploded = left.merge(right, on='k', how='inner')\n",
        "print('left rows', len(left), 'right rows', len(right), 'merged rows', len(exploded))\n",
        "\n",
        "# TODO: Fix (example: deduplicate right to 1 row per k)\n",
        "right_dedup = right.drop_duplicates('k', keep='first')\n",
        "fixed = left.merge(right_dedup, on='k', how='inner')\n",
        "print('fixed rows', len(fixed))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4 — Time-based Features & Leakage (FAANG System Thinking)\n",
        "\n",
        "### Task 4.1: Leakage-safe feature\n",
        "\n",
        "For each user and each event row, compute `purchases_before` = number of purchases strictly BEFORE that `event_ts`.\n",
        "\n",
        "Constraints:\n",
        "- No Python loops over rows\n",
        "- Must be time-aware\n",
        "\n",
        "# HINT:\n",
        "- Sort by user_id, event_ts\n",
        "- Create boolean `is_purchase`\n",
        "- Use groupby + cumsum, then shift\n",
        "\n",
        "**FAANG gotcha:** If you include the current row in the count, you leak label info for purchase events.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: nonnegative\n",
            "   user_id   event_ts        event  purchases_before\n",
            "0      101 2025-01-02         view                 0\n",
            "1      101 2025-01-06  add_to_cart                 0\n",
            "2      101 2025-01-10     purchase                 0\n",
            "3      101 2025-01-11         view                 1\n",
            "4      101 2025-01-14  add_to_cart                 0\n",
            "5      101 2025-01-20         view                 0\n",
            "6      102 2025-01-01         view                 0\n",
            "7      102 2025-01-16  add_to_cart                 0\n",
            "8      102 2025-01-17         view                 0\n",
            "9      102 2025-01-18  add_to_cart                 0\n"
          ]
        }
      ],
      "source": [
        "# Data Leakage : When information from outside the training dataset is used to create the model.\n",
        "# TODO\n",
        "events3 = events.copy().sort_values(['user_id', 'event_ts']).reset_index(drop=True)\n",
        "events3['is_purchase'] = (events3['event'] == 'purchase').astype(int)\n",
        "\n",
        "# purchases up to and including current row\n",
        "events3['purchases_cum'] = events3.groupby('user_id')['is_purchase'].cumsum()\n",
        "\n",
        "# TODO: leakage-safe: purchases strictly before current row\n",
        "events3['purchases_before'] = events3.groupby('user_id')['is_purchase'].shift(1).fillna(0).astype(int)\n",
        "\n",
        "check('nonnegative', (events3['purchases_before'] >= 0).all())\n",
        "print(events3[['user_id','event_ts','event','purchases_before']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5 — Apply vs Vectorization\n",
        "\n",
        "### Task 5.1: Remove slow apply\n",
        "\n",
        "Create a `country_is_in` boolean column on `users`.\n",
        "- First: do it with `.apply(...)` (slow style)\n",
        "- Then: replace it with vectorized code\n",
        "\n",
        "**Explain:** Why is `.apply` often slower in Pandas?\n",
        "- Vectorize version is faster beacuse they operate on contiguous memory using compiled C code, avoiding Python loops.\n",
        "- SIMD(single instruction multiple data) which allows CPU to read multiple data in one go.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t_apply: 0.00037670135498046875\n",
            "t_vectorized: 0.0002110004425048828\n",
            "OK: same_result\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>country</th>\n",
              "      <th>signup_ts</th>\n",
              "      <th>country_is_in_apply</th>\n",
              "      <th>country_is_in</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>IN</td>\n",
              "      <td>2025-01-01</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>102</td>\n",
              "      <td>US</td>\n",
              "      <td>2025-01-03</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>103</td>\n",
              "      <td>IN</td>\n",
              "      <td>2025-01-04</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>104</td>\n",
              "      <td>CA</td>\n",
              "      <td>2025-01-10</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id country  signup_ts  country_is_in_apply  country_is_in\n",
              "0      101      IN 2025-01-01                 True           True\n",
              "1      102      US 2025-01-03                False          False\n",
              "2      103      IN 2025-01-04                 True           True\n",
              "3      104      CA 2025-01-10                False          False"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "u = users.copy()\n",
        "\n",
        "# TODO: slow style (keep for comparison)\n",
        "t1 = time.time()\n",
        "u['country_is_in_apply'] = u['country'].apply(lambda x: x == 'IN')\n",
        "t_apply = time.time() - t1\n",
        "\n",
        "# TODO: vectorized style\n",
        "# Here you just write a expression. \n",
        "t2 = time.time()\n",
        "u['country_is_in'] = u['country'] == 'IN'\n",
        "t_vectorized = time.time() - t2\n",
        "\n",
        "print('t_apply:', t_apply)\n",
        "print('t_vectorized:', t_vectorized)\n",
        "\n",
        "check('same_result', (u['country_is_in_apply'] == u['country_is_in']).all())\n",
        "u\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Submission Checklist\n",
        "- All TODOs completed\n",
        "- All checks pass\n",
        "- Explain prompts answered\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
